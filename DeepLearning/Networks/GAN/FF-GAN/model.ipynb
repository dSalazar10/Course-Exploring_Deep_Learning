{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load MINST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "0it [00:00, ?it/s]Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n9920512it [00:01, 7366001.38it/s]\nExtracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n0it [00:00, ?it/s]Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n32768it [00:00, 123745.74it/s]\n0it [00:00, ?it/s]Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n1654784it [00:00, 2283750.49it/s]\n0it [00:00, ?it/s]Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n8192it [00:00, 35106.92it/s]Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\nProcessing...\nDone!\n\n"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# number of subprocesses to use for data loading\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 64\n",
    "\n",
    "# convert data to torch.FloatTensor\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "# get the training datasets\n",
    "train_data = datasets.MNIST(root='data', train=True,\n",
    "                                   download=True, transform=transform)\n",
    "\n",
    "# prepare data loader\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "                                           num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Discriminator hyperparams\n",
    "# Size of input image to discriminator (28*28)\n",
    "input_size = 784\n",
    "# Size of discriminator output (real or fake)\n",
    "d_output_size = 1\n",
    "# Size of last hidden layer in the discriminator\n",
    "d_hidden_size = 32\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_dim, output_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        # define hidden linear layers\n",
    "        self.fc1 = nn.Linear(input_size, hidden_dim*4)\n",
    "        self.fc2 = nn.Linear(hidden_dim*4, hidden_dim*2)\n",
    "        self.fc3 = nn.Linear(hidden_dim*2, hidden_dim)\n",
    "        \n",
    "        # final fully-connected layer\n",
    "        self.fc4 = nn.Linear(hidden_dim, output_size)\n",
    "        \n",
    "        # dropout layer \n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # flatten image\n",
    "        x = x.view(-1, 28*28)\n",
    "        # all hidden layers\n",
    "        x = F.leaky_relu(self.fc1(x), 0.2) # (input, negative_slope=0.2)\n",
    "        x = self.dropout(x)\n",
    "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
    "        x = self.dropout(x)\n",
    "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
    "        x = self.dropout(x)\n",
    "        # final layer\n",
    "        out = self.fc4(x)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator hyperparams\n",
    "# Size of latent vector to give to generator\n",
    "z_size = 100\n",
    "# Size of discriminator output (generated image)\n",
    "g_output_size = 784\n",
    "# Size of first hidden layer in the generator\n",
    "g_hidden_size = 32\n",
    "\n",
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_dim, output_size):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        # define hidden linear layers\n",
    "        self.fc1 = nn.Linear(input_size, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim*2)\n",
    "        self.fc3 = nn.Linear(hidden_dim*2, hidden_dim*4)\n",
    "        \n",
    "        # final fully-connected layer\n",
    "        self.fc4 = nn.Linear(hidden_dim*4, output_size)\n",
    "        \n",
    "        # dropout layer \n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # all hidden layers\n",
    "        x = F.leaky_relu(self.fc1(x), 0.2) # (input, negative_slope=0.2)\n",
    "        x = self.dropout(x)\n",
    "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
    "        x = self.dropout(x)\n",
    "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
    "        x = self.dropout(x)\n",
    "        # final layer with tanh applied\n",
    "        out = F.tanh(self.fc4(x))\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instatiate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate discriminator and generator\n",
    "D = Discriminator(input_size, d_hidden_size, d_output_size)\n",
    "G = Generator(z_size, g_hidden_size, g_output_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate losses\n",
    "def real_loss(D_out, smooth=False):\n",
    "    batch_size = D_out.size(0)\n",
    "    # label smoothing\n",
    "    if smooth:\n",
    "        # smooth, real labels = 0.9\n",
    "        labels = torch.ones(batch_size)*0.9\n",
    "    else:\n",
    "        labels = torch.ones(batch_size) # real labels = 1\n",
    "        \n",
    "    # numerically stable loss\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    # calculate loss\n",
    "    loss = criterion(D_out.squeeze(), labels)\n",
    "    return loss\n",
    "\n",
    "def fake_loss(D_out):\n",
    "    batch_size = D_out.size(0)\n",
    "    labels = torch.zeros(batch_size) # fake labels = 0\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    # calculate loss\n",
    "    loss = criterion(D_out.squeeze(), labels)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Optimizers\n",
    "lr = 0.002\n",
    "\n",
    "# Create optimizers for the discriminator and generator\n",
    "d_optimizer = optim.Adam(D.parameters(), lr)\n",
    "g_optimizer = optim.Adam(G.parameters(), lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch [    1/  100] | d_loss: 1.3923 | g_loss: 0.7342\nEpoch [    1/  100] | d_loss: 0.8208 | g_loss: 3.1396\nEpoch [    1/  100] | d_loss: 0.9655 | g_loss: 1.2413\nEpoch [    2/  100] | d_loss: 0.9284 | g_loss: 2.7238\nEpoch [    2/  100] | d_loss: 1.2628 | g_loss: 1.1670\nEpoch [    2/  100] | d_loss: 0.9341 | g_loss: 3.0896\nEpoch [    3/  100] | d_loss: 1.2680 | g_loss: 0.7757\nEpoch [    3/  100] | d_loss: 1.0387 | g_loss: 1.1945\nEpoch [    3/  100] | d_loss: 1.0992 | g_loss: 1.0222\nEpoch [    4/  100] | d_loss: 0.8563 | g_loss: 1.9419\nEpoch [    4/  100] | d_loss: 1.4134 | g_loss: 1.4689\nEpoch [    4/  100] | d_loss: 1.0209 | g_loss: 1.0585\nEpoch [    5/  100] | d_loss: 1.0967 | g_loss: 1.6615\nEpoch [    5/  100] | d_loss: 1.0724 | g_loss: 1.1244\nEpoch [    5/  100] | d_loss: 1.0217 | g_loss: 2.3951\nEpoch [    6/  100] | d_loss: 1.0900 | g_loss: 1.5118\nEpoch [    6/  100] | d_loss: 1.2419 | g_loss: 2.1540\nEpoch [    6/  100] | d_loss: 0.9719 | g_loss: 4.2034\nEpoch [    7/  100] | d_loss: 0.8285 | g_loss: 3.4060\nEpoch [    7/  100] | d_loss: 0.7006 | g_loss: 9.2013\nEpoch [    7/  100] | d_loss: 0.6630 | g_loss: 7.8092\nEpoch [    8/  100] | d_loss: 0.8299 | g_loss: 3.0314\nEpoch [    8/  100] | d_loss: 0.6505 | g_loss: 4.7054\nEpoch [    8/  100] | d_loss: 0.8941 | g_loss: 4.3477\nEpoch [    9/  100] | d_loss: 0.7987 | g_loss: 1.9501\nEpoch [    9/  100] | d_loss: 0.9017 | g_loss: 2.4146\nEpoch [    9/  100] | d_loss: 0.7977 | g_loss: 2.7267\nEpoch [   10/  100] | d_loss: 1.1290 | g_loss: 2.1953\nEpoch [   10/  100] | d_loss: 0.7640 | g_loss: 2.8137\nEpoch [   10/  100] | d_loss: 1.0649 | g_loss: 1.4311\nEpoch [   11/  100] | d_loss: 1.2107 | g_loss: 1.1907\nEpoch [   11/  100] | d_loss: 1.1285 | g_loss: 1.1597\nEpoch [   11/  100] | d_loss: 1.2303 | g_loss: 1.5342\nEpoch [   12/  100] | d_loss: 1.2589 | g_loss: 1.4954\nEpoch [   12/  100] | d_loss: 1.2463 | g_loss: 1.3274\nEpoch [   12/  100] | d_loss: 1.2714 | g_loss: 1.3854\nEpoch [   13/  100] | d_loss: 1.2523 | g_loss: 1.2596\nEpoch [   13/  100] | d_loss: 1.2365 | g_loss: 0.9249\nEpoch [   13/  100] | d_loss: 1.2928 | g_loss: 1.0116\nEpoch [   14/  100] | d_loss: 1.2272 | g_loss: 1.0807\nEpoch [   14/  100] | d_loss: 1.2678 | g_loss: 1.0540\nEpoch [   14/  100] | d_loss: 1.4010 | g_loss: 0.9151\nEpoch [   15/  100] | d_loss: 1.3346 | g_loss: 0.8858\nEpoch [   15/  100] | d_loss: 1.4134 | g_loss: 1.5444\nEpoch [   15/  100] | d_loss: 1.4876 | g_loss: 0.7898\nEpoch [   16/  100] | d_loss: 1.2676 | g_loss: 1.0288\nEpoch [   16/  100] | d_loss: 1.2497 | g_loss: 1.0327\nEpoch [   16/  100] | d_loss: 1.3951 | g_loss: 0.9030\nEpoch [   17/  100] | d_loss: 1.3387 | g_loss: 1.0080\nEpoch [   17/  100] | d_loss: 1.2087 | g_loss: 0.9071\nEpoch [   17/  100] | d_loss: 1.3868 | g_loss: 0.8188\nEpoch [   18/  100] | d_loss: 1.2989 | g_loss: 0.9543\nEpoch [   18/  100] | d_loss: 1.2768 | g_loss: 0.9109\nEpoch [   18/  100] | d_loss: 1.3184 | g_loss: 0.9776\nEpoch [   19/  100] | d_loss: 1.3834 | g_loss: 1.0281\nEpoch [   19/  100] | d_loss: 1.2596 | g_loss: 1.9875\nEpoch [   19/  100] | d_loss: 1.4788 | g_loss: 0.9328\nEpoch [   20/  100] | d_loss: 1.2995 | g_loss: 0.8993\nEpoch [   20/  100] | d_loss: 1.3946 | g_loss: 1.0511\nEpoch [   20/  100] | d_loss: 1.2734 | g_loss: 1.1501\nEpoch [   21/  100] | d_loss: 1.2357 | g_loss: 0.9968\nEpoch [   21/  100] | d_loss: 1.1338 | g_loss: 1.4375\nEpoch [   21/  100] | d_loss: 1.2998 | g_loss: 0.9970\nEpoch [   22/  100] | d_loss: 1.2878 | g_loss: 1.1128\nEpoch [   22/  100] | d_loss: 1.2087 | g_loss: 1.1671\nEpoch [   22/  100] | d_loss: 1.3034 | g_loss: 1.2315\nEpoch [   23/  100] | d_loss: 1.1979 | g_loss: 1.0861\nEpoch [   23/  100] | d_loss: 1.2838 | g_loss: 1.2828\nEpoch [   23/  100] | d_loss: 1.2600 | g_loss: 0.8712\nEpoch [   24/  100] | d_loss: 1.2610 | g_loss: 1.2123\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a836ebce8759>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m# add up loss and perform backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_real_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0md_fake_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0md_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0md_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "# training hyperparams\n",
    "num_epochs = 100\n",
    "\n",
    "# keep track of loss and generated, \"fake\" samples\n",
    "samples = []\n",
    "losses = []\n",
    "\n",
    "print_every = 400\n",
    "\n",
    "# Get some fixed data for sampling. These are images that are held\n",
    "# constant throughout training, and allow us to inspect the model's performance\n",
    "sample_size=16\n",
    "fixed_z = np.random.uniform(-1, 1, size=(sample_size, z_size))\n",
    "fixed_z = torch.from_numpy(fixed_z).float()\n",
    "\n",
    "# train the network\n",
    "D.train()\n",
    "G.train()\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for batch_i, (real_images, _) in enumerate(train_loader):\n",
    "                \n",
    "        batch_size = real_images.size(0)\n",
    "        \n",
    "        ## Important rescaling step ## \n",
    "        real_images = real_images*2 - 1  # rescale input images from [0,1) to [-1, 1)\n",
    "        \n",
    "        # ============================================\n",
    "        #            TRAIN THE DISCRIMINATOR\n",
    "        # ============================================\n",
    "        \n",
    "        d_optimizer.zero_grad()\n",
    "        \n",
    "        # 1. Train with real images\n",
    "\n",
    "        # Compute the discriminator losses on real images \n",
    "        # smooth the real labels\n",
    "        D_real = D(real_images)\n",
    "        d_real_loss = real_loss(D_real, smooth=True)\n",
    "        \n",
    "        # 2. Train with fake images\n",
    "        \n",
    "        # Generate fake images\n",
    "        z = np.random.uniform(-1, 1, size=(batch_size, z_size))\n",
    "        z = torch.from_numpy(z).float()\n",
    "        fake_images = G(z)\n",
    "        \n",
    "        # Compute the discriminator losses on fake images        \n",
    "        D_fake = D(fake_images)\n",
    "        d_fake_loss = fake_loss(D_fake)\n",
    "        \n",
    "        # add up loss and perform backprop\n",
    "        d_loss = d_real_loss + d_fake_loss\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        \n",
    "        # =========================================\n",
    "        #            TRAIN THE GENERATOR\n",
    "        # =========================================\n",
    "        g_optimizer.zero_grad()\n",
    "        \n",
    "        # 1. Train with fake images and flipped labels\n",
    "        \n",
    "        # Generate fake images\n",
    "        z = np.random.uniform(-1, 1, size=(batch_size, z_size))\n",
    "        z = torch.from_numpy(z).float()\n",
    "        fake_images = G(z)\n",
    "        \n",
    "        # Compute the discriminator losses on fake images \n",
    "        # using flipped labels!\n",
    "        D_fake = D(fake_images)\n",
    "        g_loss = real_loss(D_fake) # use real loss to flip labels\n",
    "        \n",
    "        # perform backprop\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "\n",
    "        # Print some loss stats\n",
    "        if batch_i % print_every == 0:\n",
    "            # print discriminator and generator loss\n",
    "            print('Epoch [{:5d}/{:5d}] | d_loss: {:6.4f} | g_loss: {:6.4f}'.format(\n",
    "                    epoch+1, num_epochs, d_loss.item(), g_loss.item()))\n",
    "\n",
    "    \n",
    "    ## AFTER EACH EPOCH##\n",
    "    # append discriminator loss and generator loss\n",
    "    losses.append((d_loss.item(), g_loss.item()))\n",
    "    \n",
    "    # generate and save sample, fake images\n",
    "    G.eval() # eval mode for generating samples\n",
    "    samples_z = G(fixed_z)\n",
    "    samples.append(samples_z)\n",
    "    G.train() # back to train mode\n",
    "\n",
    "\n",
    "# Save training generator samples\n",
    "with open('train_samples.pkl', 'wb') as f:\n",
    "    pkl.dump(samples, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for viewing a list of passed in sample images\n",
    "def view_samples(epoch, samples):\n",
    "    fig, axes = plt.subplots(figsize=(7,7), nrows=4, ncols=4, sharey=True, sharex=True)\n",
    "    for ax, img in zip(axes.flatten(), samples[epoch]):\n",
    "        img = img.detach()\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.yaxis.set_visible(False)\n",
    "        im = ax.imshow(img.reshape((28,28)), cmap='Greys_r')\n",
    "# Load samples from generator, taken while training\n",
    "with open('train_samples.pkl', 'rb') as f:\n",
    "    samples = pkl.load(f)\n",
    "# -1 indicates final epoch's samples (the last in the list)\n",
    "view_samples(-1, samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 10 # split epochs into 10, so 100/10 = every 10 epochs\n",
    "cols = 6\n",
    "fig, axes = plt.subplots(figsize=(7,12), nrows=rows, ncols=cols, sharex=True, sharey=True)\n",
    "\n",
    "for sample, ax_row in zip(samples[::int(len(samples)/rows)], axes):\n",
    "    for img, ax in zip(sample[::int(len(sample)/cols)], ax_row):\n",
    "        img = img.detach()\n",
    "        ax.imshow(img.reshape((28,28)), cmap='Greys_r')\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.yaxis.set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly generated, new latent vectors\n",
    "sample_size=16\n",
    "rand_z = np.random.uniform(-1, 1, size=(sample_size, z_size))\n",
    "rand_z = torch.from_numpy(rand_z).float()\n",
    "\n",
    "G.eval() # eval mode\n",
    "# generated samples\n",
    "rand_images = G(rand_z)\n",
    "\n",
    "# 0 indicates the first set of samples in the passed in list\n",
    "# and we only have one batch of samples, here\n",
    "view_samples(0, [rand_images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}